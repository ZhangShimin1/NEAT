trainer:
  num_train_epochs: 30
  seed: 202412
  output_dir: "exp/"
  optim: adam
  dataloader_num_workers: 16
  per_device_train_batch_size: 256
  eval_batch_size: 1
  eval_epoch_interval: 10
  learning_rate: 0.001
  lr_scheduler_type: cosine_with_min_lr_schedule_with_warmup
  warmup_ratio: 0.0
  warmup_steps: 1000
  cosine_with_min_lr_schedule_with_warmup_num_cycles: 0.5
  cosine_with_min_lr_schedule_with_warmup_initial_lr: 0.001
  cosine_with_min_lr_schedule_with_warmup_min_lr: 0.0001
  metric_for_best_model: "cosine_eer"
  greater_is_better: false

model:
  network:
    num_hidden_layers: 2
    num_hidden_units: [512, 512]
    recurrent_layer: []

  neuron:
    surrogate_gradient: "atan"
    reset: "hard"
    tau: 2.
    v_threshold: 0.5

loss_name: "amsoftmax"
emb_dim: 256
num_classes: 5994