trainer:
  num_train_epochs: 30
  seed: 202412
  output_dir: "exp/"
  optim: adam
  dataloader_num_workers: 16
  per_device_train_batch_size: 256
  eval_batch_size: 1
  eval_epoch_interval: 10
  learning_rate: 0.001
  lr_scheduler_type: cosine_with_min_lr_schedule_with_warmup
  warmup_ratio: 0.0
  warmup_steps: 1000
  cosine_with_min_lr_schedule_with_warmup_num_cycles: 0.5
  cosine_with_min_lr_schedule_with_warmup_initial_lr: 0.001
  cosine_with_min_lr_schedule_with_warmup_min_lr: 0.0001
  metric_for_best_model: "cosine_eer"
  greater_is_better: false


model:
  network:
    num_hidden_layers: 3
    num_hidden_units: [64, 256, 64]
    recurrent_layer: [0, 1]

  neuron:
    neuron_class: "RLIF"
    args:
      rest: 0.0
      decay: 0.2
      threshold: 0.3
      exec_mode: "serial"
      surro_grad: "triangle"  # Example surrogate gradient

loss_name: "amsoftmax"
emb_dim: 256
num_classes: 5994